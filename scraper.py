import time
import requests
import trafilatura
import re
import random
import os
from datetime import datetime

try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    
from config import SENSORTOWER_URL, APP_ID, SELENIUM_DRIVER_PATH, SELENIUM_HEADLESS, SELENIUM_TIMEOUT, TELEGRAM_BOT_TOKEN, TELEGRAM_SOURCE_CHANNEL
from logger import logger

class SensorTowerScraper:
    def __init__(self):
        self.url = SENSORTOWER_URL
        self.app_id = APP_ID
        self.driver = None
        self.last_scrape_data = None
        self.telegram_source_channel = TELEGRAM_SOURCE_CHANNEL  # –ö–∞–Ω–∞–ª, –æ—Ç–∫—É–¥–∞ –±–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ
        self.limit = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    def initialize_driver(self):
        """Initialize the Selenium WebDriver"""
        try:
            chrome_options = Options()
            if SELENIUM_HEADLESS:
                chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            
            service = Service(executable_path=SELENIUM_DRIVER_PATH)
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.set_page_load_timeout(SELENIUM_TIMEOUT)
            logger.info("Selenium WebDriver initialized successfully")
            return True
        except WebDriverException as e:
            logger.error(f"Failed to initialize WebDriver: {str(e)}")
            return False

    def close_driver(self):
        """Close the Selenium WebDriver"""
        if self.driver:
            self.driver.quit()
            logger.info("Selenium WebDriver closed")

    def _create_test_data(self):
        """
        Create test data for development purposes
        """
        logger.info("Using test data for development")
        
        # Generate a consistent test dataset for US - iPhone - Top Free —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º –≤—ã—à–µ 200
        app_name = "Coinbase"
        
        rankings_data = {
            "app_name": app_name,
            "app_id": self.app_id,
            "date": time.strftime("%Y-%m-%d"),
            "categories": [
                {"category": "US - iPhone - Top Free", "rank": "237"}
            ]
        }
        
        self.last_scrape_data = rankings_data
        return rankings_data

    def _get_messages_from_telegram(self):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–∞ Telegram —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞
        """
        try:
            # –ü–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –Ω–µ—Ç –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –≤ –∫–∞–Ω–∞–ª–µ, –º—ã –Ω–µ –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Bot API
            # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –º—ã –±—É–¥–µ–º –ø–∞—Ä—Å–∏—Ç—å –ø—É–±–ª–∏—á–Ω—É—é –≤–µ–±-–≤–µ—Ä—Å–∏—é –∫–∞–Ω–∞–ª–∞
            
            channel_username = self.telegram_source_channel.replace("@", "")
            url = f"https://t.me/s/{channel_username}"
            
            logger.info(f"Attempting to scrape web version of channel: {url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            try:
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code != 200:
                    logger.error(f"Failed to fetch channel web page: HTTP {response.status_code}")
                    return None
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º trafilatura –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML
                html_content = response.text
                messages = []
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–ª–æ–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
                message_blocks = re.findall(r'<div class="tgme_widget_message_text[^>]*>(.*?)</div>', html_content, re.DOTALL)
                
                if message_blocks:
                    for block in message_blocks:
                        # –û—á–∏—â–∞–µ–º HTML-—Ç–µ–≥–∏ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
                        clean_text = re.sub(r'<[^>]+>', ' ', block)
                        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
                        if clean_text:
                            messages.append(clean_text)
                            
                    logger.info(f"Found {len(messages)} messages from the channel web page")
                else:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    text_content = trafilatura.extract(html_content)
                    if text_content:
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
                        paragraphs = re.split(r'\n+', text_content)
                        messages = [p.strip() for p in paragraphs if p.strip()]
                        logger.info(f"Extracted {len(messages)} paragraphs using trafilatura")
                
                return messages
                
            except requests.exceptions.RequestException as e:
                logger.error(f"Request failed: {str(e)}")
                return None
                
        except Exception as e:
            logger.error(f"Error getting messages from Telegram web: {str(e)}")
            return None
    
    def _extract_ranking_from_message(self, message):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ä–µ–π—Ç–∏–Ω–≥–µ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è Telegram
        
        Args:
            message (str): –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram
            
        Returns:
            int or None: –ó–Ω–∞—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å
        """
        try:
            if not message:
                return None
                
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
            
            # –í–∞—Ä–∏–∞–Ω—Ç 1: –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è: X
            pattern1 = r"–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è:?\s*\*?(\d+)\*?"
            match = re.search(pattern1, message)
            
            if match:
                rank = int(match.group(1))
                logger.info(f"Extracted ranking using pattern 1: {rank}")
                return rank
            
            # –í–∞—Ä–∏–∞–Ω—Ç 2: –¢–µ–∫—É—â–µ–µ –º–µ—Å—Ç–æ: X
            pattern2 = r"–¢–µ–∫—É—â–µ–µ –º–µ—Å—Ç–æ:?\s*\*?(\d+)\*?"
            match = re.search(pattern2, message)
            
            if match:
                rank = int(match.group(1))
                logger.info(f"Extracted ranking using pattern 2: {rank}")
                return rank
            
            # –í–∞—Ä–∏–∞–Ω—Ç 3: Rank: X –∏–ª–∏ Position: X
            pattern3 = r"(?:Rank|Position|–ü–æ–∑–∏—Ü–∏—è|–ú–µ—Å—Ç–æ):?\s*\*?#?(\d+)\*?"
            match = re.search(pattern3, message, re.IGNORECASE)
            
            if match:
                rank = int(match.group(1))
                logger.info(f"Extracted ranking using pattern 3: {rank}")
                return rank
            
            # –í–∞—Ä–∏–∞–Ω—Ç 4: –ò—â–µ–º –ø—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä—É —Å —Ä–µ—à–µ—Ç–∫–æ–π (#123)
            pattern4 = r"#(\d+)"
            match = re.search(pattern4, message)
            
            if match:
                rank = int(match.group(1))
                logger.info(f"Extracted ranking using pattern 4: {rank}")
                return rank
            
            logger.warning(f"Could not extract ranking from message: {message[:100]}...")
            return None
        except Exception as e:
            logger.error(f"Error extracting ranking: {str(e)}")
            return None
    
    def _fallback_scrape_with_trafilatura(self):
        """
        Fallback method to scrape data using trafilatura when Telegram and Selenium fail
        """
        logger.info("Attempting fallback scraping with trafilatura")
        
        try:
            # Use requests to get the page content
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            try:
                response = requests.get(self.url, headers=headers, timeout=10)
                
                if response.status_code != 200:
                    logger.error(f"Failed to fetch page: HTTP {response.status_code}")
                    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ App Store –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
                    return self._scrape_from_app_store()
                    
                # Extract text content using trafilatura
                downloaded = response.text
                text_content = trafilatura.extract(downloaded)
                
                if not text_content:
                    logger.error("Trafilatura failed to extract any content")
                    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ App Store –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
                    return self._scrape_from_app_store()
                    
                logger.info("Successfully extracted content with trafilatura")
                
                # Use the fallback test data anyway since we can't reliably parse the SensorTower data
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ App Store –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
                return self._scrape_from_app_store()
                
            except requests.exceptions.RequestException as e:
                logger.error(f"Request failed: {str(e)}")
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ App Store –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
                return self._scrape_from_app_store()
                
        except Exception as e:
            logger.error(f"Fallback scraping failed: {str(e)}")
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ App Store –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ
            return self._scrape_from_app_store()
            
    def _scrape_from_app_store(self):
        """
        Scrape data directly from the App Store
        
        Returns:
            dict: A dictionary containing the ranking data
        """
        logger.info("Attempting to scrape data from App Store")
        
        try:
            # App ID –¥–ª—è Coinbase –≤ App Store
            app_id = "886427730"
            app_store_url = f"https://apps.apple.com/us/app/coinbase-buy-bitcoin-crypto/id{app_id}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
                'Accept-Language': 'en-US,en;q=0.9'
            }
            
            response = requests.get(app_store_url, headers=headers, timeout=15)
            
            if response.status_code != 200:
                logger.error(f"Failed to fetch App Store page: HTTP {response.status_code}")
                return self._create_test_data()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º trafilatura –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            html_content = response.text
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥ –∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã App Store
            # –û–±—ã—á–Ω–æ App Store –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞–ø—Ä—è–º—É—é,
            # –Ω–æ –º—ã –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤
            ratings_pattern = r'"ratingCount":(\d+),'
            rating_count_match = re.search(ratings_pattern, html_content)
            
            ratings_value_pattern = r'"averageRating":([\d\.]+),'
            rating_value_match = re.search(ratings_value_pattern, html_content)
            
            # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∑–∏—Ü–∏–∏ –≤ —á–∞—Ä—Ç–∞—Ö
            chart_position_pattern = r'#(\d+) in ([^"]+)'
            chart_position_match = re.search(chart_position_pattern, html_content)
            
            app_name = "Coinbase"
            date = time.strftime("%Y-%m-%d")
            
            if chart_position_match:
                rank = chart_position_match.group(1)
                category = chart_position_match.group(2).strip()
                
                logger.info(f"Found App Store ranking: #{rank} in {category}")
                
                rankings_data = {
                    "app_name": app_name,
                    "app_id": self.app_id,
                    "date": date,
                    "categories": [
                        {"category": "US - iPhone - Top Free", "rank": rank}
                    ]
                }
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö –∏ –æ—Ç–∑—ã–≤–∞—Ö, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö
                if rating_count_match and rating_value_match:
                    rating_count = rating_count_match.group(1)
                    rating_value = rating_value_match.group(1)
                    logger.info(f"Found App Store ratings: {rating_value}/5 from {rating_count} reviews")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                self.last_scrape_data = rankings_data
                return rankings_data
            else:
                logger.error("Could not find chart position in App Store page")
                return self._create_test_data()
                
        except Exception as e:
            logger.error(f"Error scraping from App Store: {str(e)}")
            return self._create_test_data()
    
    def scrape_category_rankings(self):
        """
        Scrape the category rankings data from Telegram channel @coinbaseappstore
        
        Returns:
            dict: A dictionary containing the scraped rankings data
        """
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Telegram
        logger.info(f"Attempting to get ranking data from Telegram channel: {self.telegram_source_channel}")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram –∫–∞–Ω–∞–ª–∞
            messages = self._get_messages_from_telegram()
            
            if not messages or len(messages) == 0:
                logger.warning("No messages retrieved from Telegram channel")
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–ø–∞—Å–Ω–æ–º—É –º–µ—Ç–æ–¥—É - SensorTower
                logger.info("Falling back to SensorTower scraping")
                return self._scrape_from_sensortower()
            
            # –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–µ–π—Ç–∏–Ω–≥–æ–º
            ranking = None
            message_with_ranking = None
            
            for message in messages:
                extracted_ranking = self._extract_ranking_from_message(message)
                if extracted_ranking is not None:
                    ranking = extracted_ranking
                    message_with_ranking = message
                    break
            
            if ranking is None:
                logger.warning("Could not find ranking in any of the messages")
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–ø–∞—Å–Ω–æ–º—É –º–µ—Ç–æ–¥—É - SensorTower
                logger.info("Falling back to SensorTower scraping")
                return self._scrape_from_sensortower()
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–ª—É—á–µ–Ω–Ω—ã–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º
            app_name = "Coinbase"
            
            rankings_data = {
                "app_name": app_name,
                "app_id": self.app_id,
                "date": time.strftime("%Y-%m-%d"),
                "categories": [
                    {"category": "US - iPhone - Top Free", "rank": str(ranking)}
                ]
            }
            
            logger.info(f"Successfully scraped ranking from Telegram: {ranking}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            self.last_scrape_data = rankings_data
            return rankings_data
            
        except Exception as e:
            logger.error(f"Error scraping from Telegram: {str(e)}")
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–ø–∞—Å–Ω–æ–º—É –º–µ—Ç–æ–¥—É - SensorTower
            logger.info("Falling back to SensorTower scraping due to error")
            return self._scrape_from_sensortower()
    
    def _scrape_from_sensortower(self):
        """
        Fallback method to scrape data from SensorTower when Telegram fails
        
        Returns:
            dict: A dictionary containing the scraped rankings data
        """
        if not SELENIUM_AVAILABLE:
            logger.warning("Selenium is not available, using fallback method")
            return self._fallback_scrape_with_trafilatura()
            
        if not self.initialize_driver():
            logger.warning("Failed to initialize Selenium driver, using fallback method")
            return self._fallback_scrape_with_trafilatura()
        
        try:
            logger.info(f"Navigating to {self.url}")
            self.driver.get(self.url)
            
            # Wait for the page to load and accept cookies if necessary
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "button[data-testid='cookie-banner-accept-button']"))
                )
                accept_cookies_button = self.driver.find_element(By.CSS_SELECTOR, "button[data-testid='cookie-banner-accept-button']")
                accept_cookies_button.click()
                logger.info("Accepted cookies dialog")
            except:
                logger.info("No cookies dialog found or already accepted")
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏
            logger.info("Waiting for content to load...")
            try:
                # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                WebDriverWait(self.driver, SELENIUM_TIMEOUT).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div.chart-container"))
                )
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                time.sleep(8)
                
                logger.info("Page content loaded, extracting data...")
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è - –æ–±—ã—á–Ω–æ "Coinbase"
                app_name = "Coinbase"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ

                # –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ - –∏—â–µ–º –Ω—É–∂–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ XPath
                # –ù–∞–º –Ω—É–∂–µ–Ω —Ä–µ–π—Ç–∏–Ω–≥ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "US - iPhone - Top Free"
                try:
                    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º –≤—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º XPath, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –ª–∏–±–æ –±–æ–ª–µ–µ –æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ 
                    logger.info("Searching for ranking element...")
                    
                    # –ú–µ—Ç–æ–¥ 1: –ü–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É XPath
                    try:
                        rank_element = self.driver.find_element(By.XPATH, "//*[@id=':rd:']/div[5]/div/div[2]/div/div/div[2]/div[2]/div/p")
                        logger.info("Found element by provided XPath")
                    except:
                        logger.info("Could not find element by provided XPath, trying alternative method")
                        # –ú–µ—Ç–æ–¥ 2: –ë–æ–ª–µ–µ –æ–±—â–∏–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                        rank_elements = self.driver.find_elements(By.XPATH, "//div[contains(text(), 'US - iPhone - Top Free')]/following-sibling::div//p")
                        if rank_elements:
                            rank_element = rank_elements[0]
                        else:
                            # –ú–µ—Ç–æ–¥ 3: –ï—â—ë –±–æ–ª–µ–µ –æ–±—â–∏–π –ø–æ–∏—Å–∫
                            rank_elements = self.driver.find_elements(By.CSS_SELECTOR, "div.chart-container p")
                            rank_element = rank_elements[0] if rank_elements else None
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞, –µ—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω
                    if rank_element:
                        rank_text = rank_element.text.strip()
                        logger.info(f"Found ranking text: {rank_text}")
                        
                        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                        rankings_data = {
                            "app_name": app_name,
                            "app_id": self.app_id,
                            "date": time.strftime("%Y-%m-%d"),
                            "categories": [
                                {"category": "US - iPhone - Top Free", "rank": rank_text}
                            ]
                        }
                        
                        logger.info(f"Successfully scraped rank for category: US - iPhone - Top Free")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                        self.last_scrape_data = rankings_data
                        return rankings_data
                    else:
                        logger.error("Could not find ranking element on the page")
                        self.driver.save_screenshot("sensortower_debug.png")
                        logger.info("Taking screenshot for debugging")
                        return self._create_test_data()
                        
                except Exception as e:
                    logger.error(f"Error extracting rankings: {str(e)}")
                    self.driver.save_screenshot("sensortower_error.png")
                    logger.info("Taking screenshot for error debugging")
                    return self._create_test_data()
                    
            except TimeoutException:
                logger.error("Timeout waiting for page content to load")
                return self._create_test_data()
            
        except TimeoutException:
            logger.error(f"Timeout while loading the page: {self.url}")
            return self._create_test_data()
        except Exception as e:
            logger.error(f"Error while scraping SensorTower: {str(e)}")
            return self._create_test_data()
        finally:
            self.close_driver()

    def format_rankings_message(self, rankings_data):
        """
        Format the rankings data into a readable message for Telegram
        
        Args:
            rankings_data (dict): The scraped rankings data
            
        Returns:
            str: Formatted message for Telegram
        """
        if not rankings_data or "categories" not in rankings_data:
            return "‚ùå Failed to retrieve rankings data\\."
        
        # Telegram MarkdownV2 —Ç—Ä–µ–±—É–µ—Ç —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤:
        # _ * [ ] ( ) ~ ` > # + - = | { } . !
        app_name = rankings_data.get("app_name", "Unknown App")
        app_name = app_name.replace("-", "\\-").replace(".", "\\.").replace("!", "\\!")
        
        date = rankings_data.get("date", "Unknown Date")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        message = f"üìä *{app_name} –†–µ–π—Ç–∏–Ω–≥ –≤ App Store*\n"
        message += f"üìÖ *–î–∞—Ç–∞:* {date}\n\n"
        
        if not rankings_data["categories"]:
            message += "–î–∞–Ω–Ω—ã–µ –æ —Ä–µ–π—Ç–∏–Ω–≥–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\\."
        else:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ US - iPhone - Top Free
            for category in rankings_data["categories"]:
                cat_name = category.get("category", "Unknown Category")
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                cat_name = cat_name.replace("-", "\\-").replace(".", "\\.").replace("!", "\\!")
                rank = category.get("rank", "N/A")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞
                if int(rank) <= 10:
                    rank_icon = "ü•á"  # –ó–æ–ª–æ—Ç–æ –¥–ª—è —Ç–æ–ø-10
                elif int(rank) <= 50:
                    rank_icon = "ü•à"  # –°–µ—Ä–µ–±—Ä–æ –¥–ª—è —Ç–æ–ø-50
                elif int(rank) <= 100:
                    rank_icon = "ü•â"  # –ë—Ä–æ–Ω–∑–∞ –¥–ª—è —Ç–æ–ø-100
                elif int(rank) <= 200:
                    rank_icon = "üìä"  # –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Ç–æ–ø-200
                else:
                    rank_icon = "üìâ"  # –ì—Ä–∞—Ñ–∏–∫–∏ –≤–Ω–∏–∑ –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ –Ω–∏–∂–µ 200
                
                message += f"{rank_icon} *{cat_name}*\n"
                message += f"   –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è: *\\#{rank}*\n"
        
        return message
